{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "DATA_PATH = './data/'\n",
    "SOME_FREE_SONGTEXT = \"So one night I said to Kathy We gotta get away somehow Go somewhere south and somewhere warm But for God's sake let's go now. And Kathy she sort of looks at me And asks where I wanna go So I look back and I hear me say I don't care but we gotta go chorus and key change And all the other people Who slepwalk thru their days Just sort of faded out of sight When we two drove away And ev'ry day we travelled We were lookin' to get wise And we learned what was the truth And we learned what were the lies And in LA we bought a bus Sort of old and not too smart So for six hundred and fifty bucks We got out and made a start We hit the road down to the South And drove into Mexico That old bus was some old wreck But it just kept us on the road. chorus etc We drove up to Alabam And a farmer gave us some jobs We worked them crops all night and day And at night we slept like dogs We got paid and Kathy said to me It's time to make a move again And when I looked into her eyes I saw more than a friend. chorus etc And now we've stopped our travels And we sold the bus in Texas And we made our home in Austin And for sure it ain't no palace And Kathy and me we settled down And now our first kid's on the way Kathy and me and that old bus We did real good to get away.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_songs(filename, nrows=None):\n",
    "        return pd.read_csv(filename, sep='\\t', nrows=nrows)\n",
    "\n",
    "\n",
    "def load_artists(filename, nrows=None):\n",
    "        return pd.read_csv(filename, sep=',', nrows=nrows)\n",
    "\n",
    "def load_albums(filename, nrows=None):\n",
    "        return pd.read_csv(filename, sep='\\t', nrows=nrows)\n",
    "\n",
    "def random_key_from_dict(dictionary, seed=123):\n",
    "        keys_list = list(dictionary.keys())\n",
    "        np.random.seed(seed)\n",
    "        random_index = np.random.choice(len(keys_list))\n",
    "        return keys_list[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Quick overview over some columns\n",
    "df = load_songs('wasabi_songs.csv', nrows=2000)\n",
    "for property in ['artist', 'title', 'publicationDateAlbum', 'album_genre',\n",
    "                 'valence', 'arousal', 'valence_predicted', 'arousal_predicted', 'bpm']:\n",
    "    print('Histogram for:', property)\n",
    "    print(pd.value_counts(df[property]), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Step: Make new df with all relevant features we want to incorporate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       Unnamed: 0                                 _id abstract   \n",
      "0              0  ObjectId(5714dec325ac0d8aee3804e7)      NaN  \\\n",
      "1              1  ObjectId(5714dec325ac0d8aee3804e8)      NaN   \n",
      "2              2  ObjectId(5714dec325ac0d8aee3804e9)      NaN   \n",
      "3              3  ObjectId(5714dec325ac0d8aee3804ea)      NaN   \n",
      "4              4  ObjectId(5714dec325ac0d8aee3804eb)      NaN   \n",
      "...          ...                                 ...      ...   \n",
      "1995        1995  ObjectId(5714dec325ac0d8aee380cb2)      NaN   \n",
      "1996        1996  ObjectId(5714dec325ac0d8aee380cb3)      NaN   \n",
      "1997        1997  ObjectId(5714dec325ac0d8aee380cb4)      NaN   \n",
      "1998        1998  ObjectId(5714dec325ac0d8aee380cb5)      NaN   \n",
      "1999        1999  ObjectId(5714dec325ac0d8aee380cb6)      NaN   \n",
      "\n",
      "                 albumTitle       album_genre animux_content animux_contents   \n",
      "0     How Ace Are Buildings  Alternative Rock            NaN             NaN  \\\n",
      "1     How Ace Are Buildings  Alternative Rock            NaN             NaN   \n",
      "2     How Ace Are Buildings  Alternative Rock            NaN             NaN   \n",
      "3     How Ace Are Buildings  Alternative Rock            NaN             NaN   \n",
      "4     How Ace Are Buildings  Alternative Rock            NaN             NaN   \n",
      "...                     ...               ...            ...             ...   \n",
      "1995                 Realis               NaN            NaN             NaN   \n",
      "1996                 Realis               NaN            NaN             NaN   \n",
      "1997                 Realis               NaN            NaN             NaN   \n",
      "1998                 Realis               NaN            NaN             NaN   \n",
      "1999                 Realis               NaN            NaN             NaN   \n",
      "\n",
      "     animux_path animux_paths  arousal  ...   \n",
      "0            NaN           []      NaN  ...  \\\n",
      "1            NaN           []      NaN  ...   \n",
      "2            NaN           []      NaN  ...   \n",
      "3            NaN           []      NaN  ...   \n",
      "4            NaN           []      NaN  ...   \n",
      "...          ...          ...      ...  ...   \n",
      "1995         NaN           []      NaN  ...   \n",
      "1996         NaN           []      NaN  ...   \n",
      "1997         NaN           []      NaN  ...   \n",
      "1998         NaN           []      NaN  ...   \n",
      "1999         NaN           []      NaN  ...   \n",
      "\n",
      "                                         urlMusicBrainz urlPandora   \n",
      "0     http://musicbrainz.org/recording/3db608e4-eb72...        NaN  \\\n",
      "1     http://musicbrainz.org/recording/84feea0c-187f...        NaN   \n",
      "2     http://musicbrainz.org/recording/f9303efd-b512...        NaN   \n",
      "3     http://musicbrainz.org/recording/52ef8537-c61d...        NaN   \n",
      "4     http://musicbrainz.org/recording/53ae7abb-e5c8...        NaN   \n",
      "...                                                 ...        ...   \n",
      "1995                                                NaN        NaN   \n",
      "1996                                                NaN        NaN   \n",
      "1997                                                NaN        NaN   \n",
      "1998                                                NaN        NaN   \n",
      "1999                                                NaN        NaN   \n",
      "\n",
      "                                                urlSong urlSpotify   \n",
      "0                  http://lyrics.wikia.com/A:Turn_It_Up        NaN  \\\n",
      "1                     http://lyrics.wikia.com/A:Foghorn        NaN   \n",
      "2               http://lyrics.wikia.com/A:Cheeky_Monkey        NaN   \n",
      "3                       http://lyrics.wikia.com/A:No._1        NaN   \n",
      "4                    http://lyrics.wikia.com/A:Bad_Idea        NaN   \n",
      "...                                                 ...        ...   \n",
      "1995  http://lyrics.wikia.com/A_Hope_For_Home:Wither...        NaN   \n",
      "1996  http://lyrics.wikia.com/A_Hope_For_Home:The_Ma...        NaN   \n",
      "1997   http://lyrics.wikia.com/A_Hope_For_Home:No_Light        NaN   \n",
      "1998  http://lyrics.wikia.com/A_Hope_For_Home:Post_T...        NaN   \n",
      "1999  http://lyrics.wikia.com/A_Hope_For_Home:First_...        NaN   \n",
      "\n",
      "     urlWikipedia urlYouTube  urlYouTubeExist valence valence_predicted writer  \n",
      "0             NaN        NaN              NaN     NaN          0.657853    NaN  \n",
      "1             NaN        NaN              NaN     NaN         -0.810233    NaN  \n",
      "2             NaN        NaN              NaN     NaN          0.223842    NaN  \n",
      "3             NaN        NaN              NaN     NaN         -0.016932    NaN  \n",
      "4             NaN        NaN              NaN     NaN          0.339134    NaN  \n",
      "...           ...        ...              ...     ...               ...    ...  \n",
      "1995          NaN        NaN              NaN     NaN         -0.347331    NaN  \n",
      "1996          NaN        NaN              NaN     NaN         -0.347331    NaN  \n",
      "1997          NaN        NaN              NaN     NaN         -0.347331    NaN  \n",
      "1998          NaN        NaN              NaN     NaN         -0.347331    NaN  \n",
      "1999          NaN        NaN              NaN     NaN         -0.347331    NaN  \n",
      "\n",
      "[2000 rows x 78 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)\n",
    "features = df[[\"title\",\"artist\", \"album_genre\", \"valence\", \"publicationDateAlbum\"]]\n",
    "\n",
    "X = features\n",
    "y = df[\"bpm\"] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size = .75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
